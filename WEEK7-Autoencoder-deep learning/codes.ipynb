{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly detection in Oklahoma purchase credit card transactions by neural network\n",
    "\n",
    "### Author: Huizhe (Sunny) Zhu- hz2657\n",
    "\n",
    "The Office of Management and Enterprise Services in the State of Oklahoma has made its [purchase credit card transactions](https://catalog.data.gov/dataset/purchase-card-pcard-fiscal-year-2014) available. This dataset contains information on purchases made through the purchase card programs administered by the state and higher education institutions. \n",
    "\n",
    "Goal:\n",
    "\n",
    "Use Autoencoder and iForest algorithms in PyOD to apply to the dataset in order to find abnormal transactions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. load data, construct features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "from pyod.models.knn import KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_Month</th>\n",
       "      <th>Agency_Number</th>\n",
       "      <th>Agency_Name</th>\n",
       "      <th>Cardholder_Last_Name</th>\n",
       "      <th>Cardholder_First_Initial</th>\n",
       "      <th>Description</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>Transaction_Date</th>\n",
       "      <th>Posted_Date</th>\n",
       "      <th>Merchant_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>201307</td>\n",
       "      <td>1000</td>\n",
       "      <td>OKLAHOMA STATE UNIVERSITY</td>\n",
       "      <td>Mason</td>\n",
       "      <td>C</td>\n",
       "      <td>GENERAL PURCHASE</td>\n",
       "      <td>890.00</td>\n",
       "      <td>NACAS</td>\n",
       "      <td>7/30/2013 0:00</td>\n",
       "      <td>7/31/2013 0:00</td>\n",
       "      <td>CHARITABLE AND SOCIAL SERVICE ORGANIZATIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>201307</td>\n",
       "      <td>1000</td>\n",
       "      <td>OKLAHOMA STATE UNIVERSITY</td>\n",
       "      <td>Mason</td>\n",
       "      <td>C</td>\n",
       "      <td>ROOM CHARGES</td>\n",
       "      <td>368.96</td>\n",
       "      <td>SHERATON HOTEL</td>\n",
       "      <td>7/30/2013 0:00</td>\n",
       "      <td>7/31/2013 0:00</td>\n",
       "      <td>SHERATON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_Month  Agency_Number                Agency_Name Cardholder_Last_Name  \\\n",
       "0      201307           1000  OKLAHOMA STATE UNIVERSITY                Mason   \n",
       "1      201307           1000  OKLAHOMA STATE UNIVERSITY                Mason   \n",
       "\n",
       "  Cardholder_First_Initial       Description  Amount          Vendor  \\\n",
       "0                        C  GENERAL PURCHASE  890.00           NACAS   \n",
       "1                        C      ROOM CHARGES  368.96  SHERATON HOTEL   \n",
       "\n",
       "  Transaction_Date     Posted_Date  \\\n",
       "0   7/30/2013 0:00  7/31/2013 0:00   \n",
       "1   7/30/2013 0:00  7/31/2013 0:00   \n",
       "\n",
       "                             Merchant_Category  \n",
       "0  CHARITABLE AND SOCIAL SERVICE ORGANIZATIONS  \n",
       "1                                     SHERATON  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. load data\n",
    "import pandas as pd\n",
    "df = pd.read_csv(r'purchase_credit_card.csv', encoding = \"ISO-8859-1\")   \n",
    "\n",
    "# change column names \n",
    "df.columns = ['Year_Month', 'Agency_Number', 'Agency_Name', 'Cardholder_Last_Name',\n",
    "      'Cardholder_First_Initial', 'Description', 'Amount', 'Vendor', 'Transaction_Date',\n",
    "      'Posted_Date', 'Merchant_Category']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create timestamp, \"time\" variable\n",
    "df['Transaction_Date'] = pd.to_datetime(df.Transaction_Date, format=\"%m/%d/%Y %H:%M\") \n",
    "\n",
    "# create \"time\" variable: days since last purchase \n",
    "df = df.sort_values(['Agency_Name', 'Transaction_Date'], ascending=[True, True])\n",
    "df['time'] = df.Transaction_Date-df.Transaction_Date.shift(1)\n",
    "\n",
    "# convert days to numeric \n",
    "df['time'] = df['time'] / pd.Timedelta(1, unit='d')\n",
    "\n",
    "# convert negative values to 0\n",
    "df.loc[(df.time < 0 ),'time'] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. construct features\n",
    "# Feature 1: Ratio of amount spend and average spending by agency and merchant category\n",
    "stat_by_agency = df.groupby(['Agency_Name', 'Merchant_Category'])['Amount'].mean()\n",
    "stat_by_agency = pd.DataFrame(stat_by_agency)\n",
    "stat_by_agency.columns = ['AVG_amount']\n",
    "df2 = pd.merge(df, stat_by_agency, how='left', on=['Agency_Name', 'Merchant_Category'])\n",
    "df2['ratio_amount_by_agency_by_category'] = df2.Amount / df2.AVG_amount\n",
    "\n",
    "# Feature 2: Ratio of amount spend and average spending by agency and transaction description\n",
    "stat_by_Description = df.groupby(['Agency_Name', 'Description'])['Amount'].mean()\n",
    "stat_by_Description = pd.DataFrame(stat_by_Description)\n",
    "stat_by_Description.columns = ['AVG_amount_by_Description']\n",
    "df2 = pd.merge(df2, stat_by_Description, how='left', on=['Agency_Name', 'Description'])\n",
    "df2['ratio_amount_by_agency_by_Description'] = df2.Amount / df2.AVG_amount_by_Description\n",
    "\n",
    "# Feature 3: Ratio of amount spend and average spending by card holder\n",
    "stat_by_cardholder = df2.groupby(['Agency_Name', 'Cardholder_Last_Name'])['Amount'].mean()\n",
    "stat_by_cardholder = pd.DataFrame(stat_by_cardholder)\n",
    "stat_by_cardholder.columns = ['stat_by_cardholder']\n",
    "df2 = pd.merge(df2, stat_by_cardholder, how='left', on=['Agency_Name', 'Cardholder_Last_Name'])\n",
    "df2['ratio_amount_by_cardholder'] = df2.Amount / df2.stat_by_cardholder\n",
    "\n",
    "# Feature 4: ratio of time since last purchase / average time spend\n",
    "AVG_time_since_lastP = df2.groupby(['Agency_Name'])['time'].sum()/ df2.groupby(['Agency_Name'])['time'].count()\n",
    "AVG_time_since_lastP = pd.DataFrame(AVG_time_since_lastP)\n",
    "AVG_time_since_lastP.columns = ['AVG_time_since_lastP']\n",
    "df2 = pd.merge(df2, AVG_time_since_lastP, how='left', on=['Agency_Name'])\n",
    "df2['Ratio_AVG_time_since_lastP']=df2.time/df2.AVG_time_since_lastP\n",
    "\n",
    "# Feature 5: ratio of time / average time spend since last transactions by card holder\n",
    "AVG_time_since_lastP_by_cardholder  = df2.groupby(['Agency_Name', 'Cardholder_Last_Name'])['time'].sum()/ df2.groupby(['Agency_Name','Cardholder_Last_Name'])['time'].count()\n",
    "AVG_time_since_lastP_by_cardholder = pd.DataFrame(AVG_time_since_lastP_by_cardholder)\n",
    "AVG_time_since_lastP_by_cardholder.columns = ['AVG_time_since_lastP_by_cardholder']\n",
    "df2 = pd.merge(df2, AVG_time_since_lastP_by_cardholder, how='left', on=['Agency_Name','Cardholder_Last_Name'])\n",
    "df2['Ratio_AVG_time_since_lastP_by_cardholder']= df2.time/df2.AVG_time_since_lastP_by_cardholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "# for unsupervised learning, it is always a safe step to standardize the predictors\n",
    "df3 = df2.loc[:, ['ratio_amount_by_agency_by_category', \n",
    "                  'ratio_amount_by_agency_by_Description',\n",
    "                   'ratio_amount_by_cardholder',  \n",
    "                  'Ratio_AVG_time_since_lastP',  \n",
    "                  'Ratio_AVG_time_since_lastP_by_cardholder'\n",
    "                 ]]\n",
    "\n",
    "# replace na with 1: ratio = 1 means no specific meaning\n",
    "df3.replace(np.nan, 1,inplace=True)\n",
    "\n",
    "# replace inf and -inf with 1\n",
    "df3.replace(np.inf, 1,inplace=True)\n",
    "df3.replace(-np.inf, 1,inplace=True)\n",
    "\n",
    "# standardize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(X_std, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Autoencoder\n",
    "\n",
    "- Autoencoder is a special type of neural network that uses the same data as both the input values and output values. The goal is to get the middle layer which reduces noises, it can also be considered as a method of dimension reduction. \n",
    "\n",
    "- Autoencoder uses non-linear transformation, if there are too many hidden layers or too many neutrons, the model tends to overfit; otherwise the model tends to underfit.\n",
    "\n",
    "- Applications of autoencoder include image noise reduction and image coloring. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 12        \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 5)                 15        \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 5)                 30        \n",
      "=================================================================\n",
      "Total params: 153\n",
      "Trainable params: 153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 199106 samples, validate on 22123 samples\n",
      "Epoch 1/100\n",
      "199106/199106 [==============================] - 48s 241us/step - loss: 26.5110 - val_loss: 0.6041\n",
      "Epoch 2/100\n",
      "199106/199106 [==============================] - 38s 193us/step - loss: 19.5733 - val_loss: 0.5260\n",
      "Epoch 3/100\n",
      "199106/199106 [==============================] - 40s 200us/step - loss: 15.8402 - val_loss: 0.5079\n",
      "Epoch 4/100\n",
      "199106/199106 [==============================] - 36s 180us/step - loss: 12.2623 - val_loss: 0.5042\n",
      "Epoch 5/100\n",
      "199106/199106 [==============================] - 42s 211us/step - loss: 11.1872 - val_loss: 0.5019\n",
      "Epoch 6/100\n",
      "199106/199106 [==============================] - 47s 236us/step - loss: 10.3795 - val_loss: 0.5010\n",
      "Epoch 7/100\n",
      "199106/199106 [==============================] - 44s 220us/step - loss: 9.6581 - val_loss: 0.5005\n",
      "Epoch 8/100\n",
      "199106/199106 [==============================] - 48s 243us/step - loss: 8.9457 - val_loss: 0.5005\n",
      "Epoch 9/100\n",
      "199106/199106 [==============================] - 64s 321us/step - loss: 8.3137 - val_loss: 0.5002\n",
      "Epoch 10/100\n",
      "199106/199106 [==============================] - 56s 284us/step - loss: 7.7515 - val_loss: 0.5000\n",
      "Epoch 11/100\n",
      "199106/199106 [==============================] - 56s 283us/step - loss: 7.2395 - val_loss: 0.4999\n",
      "Epoch 12/100\n",
      "199106/199106 [==============================] - 45s 228us/step - loss: 6.7748 - val_loss: 0.5000\n",
      "Epoch 13/100\n",
      "199106/199106 [==============================] - 54s 272us/step - loss: 6.3480 - val_loss: 0.5000\n",
      "Epoch 14/100\n",
      "199106/199106 [==============================] - 56s 280us/step - loss: 5.9628 - val_loss: 0.5000\n",
      "Epoch 15/100\n",
      "199106/199106 [==============================] - 56s 280us/step - loss: 5.5982 - val_loss: 0.4999\n",
      "Epoch 16/100\n",
      "199106/199106 [==============================] - 54s 272us/step - loss: 5.2651 - val_loss: 0.4999\n",
      "Epoch 17/100\n",
      "199106/199106 [==============================] - 54s 272us/step - loss: 5.0158 - val_loss: 0.4999\n",
      "Epoch 18/100\n",
      "199106/199106 [==============================] - 53s 264us/step - loss: 4.6093 - val_loss: 0.5001\n",
      "Epoch 19/100\n",
      "199106/199106 [==============================] - 45s 224us/step - loss: 4.3048 - val_loss: 0.5000\n",
      "Epoch 20/100\n",
      "199106/199106 [==============================] - 45s 226us/step - loss: 4.0195 - val_loss: 0.5000\n",
      "Epoch 21/100\n",
      "199106/199106 [==============================] - 53s 268us/step - loss: 3.7409 - val_loss: 0.5000\n",
      "Epoch 22/100\n",
      "199106/199106 [==============================] - 57s 284us/step - loss: 3.5398 - val_loss: 0.5000\n",
      "Epoch 23/100\n",
      "199106/199106 [==============================] - 55s 274us/step - loss: 3.2628 - val_loss: 0.4999\n",
      "Epoch 24/100\n",
      "199106/199106 [==============================] - 57s 289us/step - loss: 3.0498 - val_loss: 0.5000\n",
      "Epoch 25/100\n",
      "199106/199106 [==============================] - 56s 284us/step - loss: 2.8250 - val_loss: 0.5000\n",
      "Epoch 26/100\n",
      "199106/199106 [==============================] - 50s 250us/step - loss: 2.6154 - val_loss: 0.5003\n",
      "Epoch 27/100\n",
      "199106/199106 [==============================] - 50s 251us/step - loss: 2.4242 - val_loss: 0.4999\n",
      "Epoch 28/100\n",
      "199106/199106 [==============================] - 48s 240us/step - loss: 2.2395 - val_loss: 0.4999\n",
      "Epoch 29/100\n",
      "199106/199106 [==============================] - 48s 241us/step - loss: 2.0722 - val_loss: 0.5002\n",
      "Epoch 30/100\n",
      "199106/199106 [==============================] - 52s 263us/step - loss: 1.9208 - val_loss: 0.5000\n",
      "Epoch 31/100\n",
      "199106/199106 [==============================] - 51s 255us/step - loss: 1.7897 - val_loss: 0.5000\n",
      "Epoch 32/100\n",
      "199106/199106 [==============================] - 59s 298us/step - loss: 1.6657 - val_loss: 0.4999\n",
      "Epoch 33/100\n",
      "199106/199106 [==============================] - 60s 300us/step - loss: 1.5563 - val_loss: 0.5001\n",
      "Epoch 34/100\n",
      "199106/199106 [==============================] - 46s 230us/step - loss: 1.4608 - val_loss: 0.5000\n",
      "Epoch 35/100\n",
      "199106/199106 [==============================] - 50s 253us/step - loss: 1.3855 - val_loss: 0.5000\n",
      "Epoch 36/100\n",
      "199106/199106 [==============================] - 58s 290us/step - loss: 1.3144 - val_loss: 0.4999\n",
      "Epoch 37/100\n",
      "199106/199106 [==============================] - 57s 284us/step - loss: 1.2572 - val_loss: 0.4999\n",
      "Epoch 38/100\n",
      "199106/199106 [==============================] - 48s 240us/step - loss: 1.2069 - val_loss: 0.4999\n",
      "Epoch 39/100\n",
      "199106/199106 [==============================] - 50s 250us/step - loss: 1.1659 - val_loss: 0.4999\n",
      "Epoch 40/100\n",
      "199106/199106 [==============================] - 44s 221us/step - loss: 1.1297 - val_loss: 0.4999\n",
      "Epoch 41/100\n",
      "199106/199106 [==============================] - 40s 199us/step - loss: 1.1005 - val_loss: 0.4999\n",
      "Epoch 42/100\n",
      "199106/199106 [==============================] - 39s 195us/step - loss: 1.0838 - val_loss: 0.4999\n",
      "Epoch 43/100\n",
      "199106/199106 [==============================] - 36s 182us/step - loss: 1.0672 - val_loss: 0.4999\n",
      "Epoch 44/100\n",
      "199106/199106 [==============================] - 29s 147us/step - loss: 1.0627 - val_loss: 0.4999\n",
      "Epoch 45/100\n",
      "199106/199106 [==============================] - 29s 145us/step - loss: 1.0566 - val_loss: 0.4999\n",
      "Epoch 46/100\n",
      "199106/199106 [==============================] - 36s 182us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 47/100\n",
      "199106/199106 [==============================] - 30s 153us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 48/100\n",
      "199106/199106 [==============================] - 29s 144us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 49/100\n",
      "199106/199106 [==============================] - 33s 167us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 50/100\n",
      "199106/199106 [==============================] - 29s 148us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 51/100\n",
      "199106/199106 [==============================] - 29s 144us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 52/100\n",
      "199106/199106 [==============================] - 39s 198us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 53/100\n",
      "199106/199106 [==============================] - 45s 226us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 54/100\n",
      "199106/199106 [==============================] - 41s 208us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 55/100\n",
      "199106/199106 [==============================] - 39s 197us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 56/100\n",
      "199106/199106 [==============================] - 45s 226us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 57/100\n",
      "199106/199106 [==============================] - 46s 231us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 58/100\n",
      "199106/199106 [==============================] - 40s 202us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 59/100\n",
      "199106/199106 [==============================] - 40s 203us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 60/100\n",
      "199106/199106 [==============================] - 34s 173us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 61/100\n",
      "199106/199106 [==============================] - 42s 210us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 62/100\n",
      "199106/199106 [==============================] - 42s 213us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 63/100\n",
      "199106/199106 [==============================] - 41s 207us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 64/100\n",
      "199106/199106 [==============================] - 43s 217us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 65/100\n",
      "199106/199106 [==============================] - 47s 235us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 66/100\n",
      "199106/199106 [==============================] - 43s 218us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 67/100\n",
      "199106/199106 [==============================] - 51s 258us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 68/100\n",
      "199106/199106 [==============================] - 52s 259us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 69/100\n",
      "199106/199106 [==============================] - 55s 277us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 70/100\n",
      "199106/199106 [==============================] - 53s 265us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 71/100\n",
      "199106/199106 [==============================] - 53s 265us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 72/100\n",
      "199106/199106 [==============================] - 53s 264us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 73/100\n",
      "199106/199106 [==============================] - 52s 263us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 74/100\n",
      "199106/199106 [==============================] - 53s 264us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 75/100\n",
      "199106/199106 [==============================] - 57s 284us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 76/100\n",
      "199106/199106 [==============================] - 54s 269us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 77/100\n",
      "199106/199106 [==============================] - 42s 208us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 78/100\n",
      "199106/199106 [==============================] - 41s 204us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 79/100\n",
      "199106/199106 [==============================] - 56s 283us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 80/100\n",
      "199106/199106 [==============================] - 56s 283us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 81/100\n",
      "199106/199106 [==============================] - 56s 284us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 82/100\n",
      "199106/199106 [==============================] - 56s 279us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 83/100\n",
      "199106/199106 [==============================] - 55s 277us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 84/100\n",
      "199106/199106 [==============================] - 55s 274us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 85/100\n",
      "199106/199106 [==============================] - 55s 274us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 86/100\n",
      "199106/199106 [==============================] - 53s 268us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 87/100\n",
      "199106/199106 [==============================] - 49s 245us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 88/100\n",
      "199106/199106 [==============================] - 51s 258us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 89/100\n",
      "199106/199106 [==============================] - 2647s 13ms/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 90/100\n",
      "199106/199106 [==============================] - 19s 97us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 91/100\n",
      "199106/199106 [==============================] - 18s 89us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 92/100\n",
      "199106/199106 [==============================] - 18s 89us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 93/100\n",
      "199106/199106 [==============================] - 18s 89us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 94/100\n",
      "199106/199106 [==============================] - 18s 89us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 95/100\n",
      "199106/199106 [==============================] - 18s 89us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 96/100\n",
      "199106/199106 [==============================] - 18s 92us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 97/100\n",
      "199106/199106 [==============================] - 18s 90us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 98/100\n",
      "199106/199106 [==============================] - 18s 91us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 99/100\n",
      "199106/199106 [==============================] - 18s 90us/step - loss: 1.0556 - val_loss: 0.4999\n",
      "Epoch 100/100\n",
      "199106/199106 [==============================] - 18s 90us/step - loss: 1.0556 - val_loss: 0.4999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoEncoder(batch_size=32, contamination=0.1, dropout_rate=0.2, epochs=100,\n",
       "      hidden_activation='relu', hidden_neurons=[5, 2, 2, 5],\n",
       "      l2_regularizer=0.1,\n",
       "      loss=<function mean_squared_error at 0x000001AFB27E84C8>,\n",
       "      optimizer='adam', output_activation='sigmoid', preprocessing=True,\n",
       "      random_state=None, validation_size=0.1, verbose=1)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Model 1: clf1 has hidden_neurons = [5, 2, 2, 5]\n",
    "AutoEncoder_model = AutoEncoder(hidden_neurons =[5, 2, 2, 5])\n",
    "AutoEncoder_model.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw outlier scores from model 1 \n",
    "AutoEncoder_y_train_scores = AutoEncoder_model.decision_scores_ \n",
    "\n",
    "# get the prediction on the test data\n",
    "AutoEncoder_y_test_pred = AutoEncoder_model.predict(X_test)  # outlier labels (0 or 1)\n",
    "\n",
    "# clf.decision_function: Predict raw anomaly score of X using the fitted detector.\n",
    "AutoEncoder_y_test_scores = AutoEncoder_model.decision_function(X_test)  # outlier scores\n",
    "\n",
    "AutoEncoder_y_test_pred = pd.Series(AutoEncoder_y_test_pred)\n",
    "AutoEncoder_y_test_scores = pd.Series(AutoEncoder_y_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199163\n",
       "1     22066\n",
       "dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoEncoder_y_test_pred.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Set boundary and identify outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram for Model Clf1 Anomaly Scores\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(AutoEncoder_y_test_scores[1:2000], bins=100)  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram for AutoEncoder_model Anomaly Scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph, we can see the observations above 5 are extreme cases, we will set the boundary to be 5. We identified anomalous cases: \n",
    "- 2205 observations\n",
    "- 9.6%  of total observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    219132\n",
       "1      2097\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set boundary: 5 \n",
    "# identify outliers in cluster 1\n",
    "X_test = pd.DataFrame(X_test)\n",
    "df_test = X_test.copy()\n",
    "df_test['score'] = AutoEncoder_y_test_scores\n",
    "df_test['cluster'] = np.where(df_test['score']<5, 0, 1)\n",
    "df_test['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009615693251590006"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of outliers: 9.6% \n",
    "2097/218081"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Describe the outliers, get summary statistics by cluster\n",
    "* We recommend observations in Cluster 1 to be outliers. \n",
    "* The attributes of Cluster 1 are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratio_amount_by_agency_by_category</th>\n",
       "      <th>ratio_amount_by_agency_by_Description</th>\n",
       "      <th>ratio_amount_by_cardholder</th>\n",
       "      <th>Ratio_AVG_time_since_lastP</th>\n",
       "      <th>Ratio_AVG_time_since_lastP_by_cardholder</th>\n",
       "      <th>anomaly scores</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.145794e-16</td>\n",
       "      <td>-2.446088e-16</td>\n",
       "      <td>-0.041776</td>\n",
       "      <td>-0.034260</td>\n",
       "      <td>-0.043593</td>\n",
       "      <td>0.518990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.244189e-03</td>\n",
       "      <td>1.234511e-01</td>\n",
       "      <td>4.232221</td>\n",
       "      <td>3.614706</td>\n",
       "      <td>4.558975</td>\n",
       "      <td>12.733886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ratio_amount_by_agency_by_category  \\\n",
       "cluster                                       \n",
       "0                             -1.145794e-16   \n",
       "1                              7.244189e-03   \n",
       "\n",
       "         ratio_amount_by_agency_by_Description  ratio_amount_by_cardholder  \\\n",
       "cluster                                                                      \n",
       "0                                -2.446088e-16                   -0.041776   \n",
       "1                                 1.234511e-01                    4.232221   \n",
       "\n",
       "         Ratio_AVG_time_since_lastP  Ratio_AVG_time_since_lastP_by_cardholder  \\\n",
       "cluster                                                                         \n",
       "0                         -0.034260                                 -0.043593   \n",
       "1                          3.614706                                  4.558975   \n",
       "\n",
       "         anomaly scores  \n",
       "cluster                  \n",
       "0              0.518990  \n",
       "1             12.733886  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary statistics\n",
    "df_test.columns = ['ratio_amount_by_agency_by_category', \n",
    "                  'ratio_amount_by_agency_by_Description',\n",
    "                   'ratio_amount_by_cardholder',  \n",
    "                  'Ratio_AVG_time_since_lastP',  \n",
    "                  'Ratio_AVG_time_since_lastP_by_cardholder', \n",
    "                   'anomaly scores', 'cluster']\n",
    "df_test.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 business insights \n",
    "\n",
    "- 9.6% outliers are identified. \n",
    "- Autoencoder has similar result with KNN. The outliers have higher spending and more time since last purchase compared compared with average level. It distinguishes the transactions that happen less frequent than usual and have higher spending. \n",
    "- It is possible that the card is stolen or lost, then being used again with more money each transaction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: iForest\n",
    "\n",
    "- Isolated Forest is a method to separate trees utill all are isolated and find which tree is the easiest to be seperated. An outlier is the easiest to be isolated. \n",
    "\n",
    "- iTree algorithm is different from the decision tree algorithm because iTree does not use a target variable to train the tree. It is an unsupervised learning method. \n",
    "\n",
    "- If there are 1,000 subsets, there will be 1,000 iTrees. Each data point in an iTree will have an anomaly score. Because there are 1,000 iTrees, each data point will have multiple anomaly scores. The average (arithmetic mean) score for a data point across all the iTrees becomes the anomaly score for that data point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IForest(behaviour='new', bootstrap=False, contamination=0.1, max_features=1.0,\n",
       "    max_samples=60, n_estimators=100, n_jobs=1, random_state=None,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.iforest import IForest\n",
    "\n",
    "#  Model 1: max_samples = 60\n",
    "clf1 = IForest(behaviour=\"new\", max_samples=60) \n",
    "clf1.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.118434\n",
       "1   -0.091982\n",
       "2   -0.193658\n",
       "3   -0.185776\n",
       "4   -0.179198\n",
       "dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict raw anomaly score of X using the fitted detector.\n",
    "# get anomaly scores: \n",
    "clf1_y_test_scores = clf1.decision_function(X_test)  # outlier scores\n",
    "clf1_y_test_scores = pd.Series(y_test_scores)\n",
    "clf1_y_test_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Set boundary and identify outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of anomaly scores\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(clf1_y_test_scores, bins=105) \n",
    "plt.title(\"Histogram for IForest Anomaly Scores\")\n",
    "plt.show()\n",
    "\n",
    "# from the graph, we identify the boundary to be: 0.05  [need to be changed, so is the code in next cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph, we can see most observations are on the left of 0. The observations above 0.2 are extreme cases, we will set the boundary to be 0.2. We got 2205 observations as outliers, they account for 1.01% of total observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    219024\n",
       "1      2205\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cluster = X_test.copy()\n",
    "X_test_cluster['distance'] = clf1_y_test_scores\n",
    "X_test_cluster['cluster'] = np.where(X_test_cluster['distance']<0.2, 0, 1)\n",
    "X_test_cluster['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010067389875082183"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show percentage of outliers\n",
    "2205/219024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Describe the outliers, get summary statistics by cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratio_amount_by_agency_by_category</th>\n",
       "      <th>ratio_amount_by_agency_by_Description</th>\n",
       "      <th>ratio_amount_by_cardholder</th>\n",
       "      <th>Ratio_AVG_time_since_lastP</th>\n",
       "      <th>Ratio_AVG_time_since_lastP_by_cardholder</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.935799e-05</td>\n",
       "      <td>1.181957e-03</td>\n",
       "      <td>-0.006190</td>\n",
       "      <td>-0.042388</td>\n",
       "      <td>-0.056681</td>\n",
       "      <td>-0.129635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.228787e-15</td>\n",
       "      <td>3.068525e-15</td>\n",
       "      <td>0.488076</td>\n",
       "      <td>4.243346</td>\n",
       "      <td>5.633590</td>\n",
       "      <td>0.222902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ratio_amount_by_agency_by_category  \\\n",
       "cluster                                       \n",
       "0                              6.935799e-05   \n",
       "1                              1.228787e-15   \n",
       "\n",
       "         ratio_amount_by_agency_by_Description  ratio_amount_by_cardholder  \\\n",
       "cluster                                                                      \n",
       "0                                 1.181957e-03                   -0.006190   \n",
       "1                                 3.068525e-15                    0.488076   \n",
       "\n",
       "         Ratio_AVG_time_since_lastP  Ratio_AVG_time_since_lastP_by_cardholder  \\\n",
       "cluster                                                                         \n",
       "0                         -0.042388                                 -0.056681   \n",
       "1                          4.243346                                  5.633590   \n",
       "\n",
       "         distance  \n",
       "cluster            \n",
       "0       -0.129635  \n",
       "1        0.222902  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary statistics \n",
    "X_test_cluster.columns = ['ratio_amount_by_agency_by_category', \n",
    "                  'ratio_amount_by_agency_by_Description',\n",
    "                   'ratio_amount_by_cardholder',  \n",
    "                  'Ratio_AVG_time_since_lastP',  \n",
    "                  'Ratio_AVG_time_since_lastP_by_cardholder', \n",
    "                   'distance', 'cluster']\n",
    "\n",
    "X_test_cluster.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 Business insights \n",
    "\n",
    "- 1.1% of total transactions are identified to be outliers. \n",
    "- Compared with Autoencoder, Iforest have slightly different patterns. From the table, we can see compared to cluster 0, cluster 1 has more spending and it takes more time for this transaction to happen on cardholder level. However, the ratios on agency level for amount spend by category and description have different patterns.\n",
    "- Insights: Outliers have more spending on cardholder level and takes more time for this transaction to happen. It is possible that the card for that cardholder is stolen or lost, then being used again. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary\n",
    "\n",
    "- Autoencoder has very similar results to KNN, the average ratios in outlier's group is higher than the rest of the observations. \n",
    "\n",
    "- iforest is slightly different compared with Autoencoder and KNN, it identifies outliers that have more spending and take more time for this transaction to happen on cardholder level but not agent level. \n",
    "\n",
    "- But in general, Autoencoder and Iforest identify similar pattern of outliers, with higher spending compared with average level, and more time since last purchase.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
